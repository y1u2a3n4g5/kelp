{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kelp Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import shuffle, seed\n",
    "# CV tools\n",
    "import tifffile as tiff\n",
    "#Visulization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Tuple\n",
    "from pathlib import Path\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "# from torchsummary import summary\n",
    "from tqdm import *\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.ticker as mticker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cuda\n"
     ]
    }
   ],
   "source": [
    "# Mac OS\n",
    "# device = \"mps\" if torch.backends.mps.is_available else \"cpu\"\n",
    "# print(f\"device is {device}\")\n",
    "# # Windows\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"device is {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "# Define your data and label folder paths\n",
    "data_dir = os.path.join(current_dir, 'data')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "label_dir = os.path.join(data_dir, 'label')\n",
    "\n",
    "temp_dir = [data_dir,train_dir,test_dir,label_dir]\n",
    "\n",
    "for dir in temp_dir:\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "# for dirpath, dirnames, filenames in os.walk(data_dir):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirpath, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini dataset folder created with the first 40 files.\n",
      "Mini dataset folder created with the first 40 files.\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "data_dir = os.path.join(current_dir, 'data')\n",
    "\n",
    "training_data_folder = os.path.join(data_dir, 'train')\n",
    "label_data_folder = os.path.join(data_dir, 'label')\n",
    "\n",
    "# Path to the mini_train folder\n",
    "mini_train_folder = os.path.join(data_dir, 'mini_train')\n",
    "mini_label_folder = os.path.join(data_dir, 'mini_label')\n",
    "\n",
    "def create_mini_dataset(source_folder, destination_folder, num_files=40):\n",
    "    \"\"\"\n",
    "    Create a mini dataset by copying a specified number of files from the source folder to the destination folder.\n",
    "\n",
    "    Args:\n",
    "    source_folder (str): Path to the source folder containing the files to be copied.\n",
    "    destination_folder (str): Path to the destination folder where the files will be copied.\n",
    "    num_files (int): Number of files to copy. Default is 40.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    # List the files in the source folder\n",
    "    files = sorted(os.listdir(source_folder))\n",
    "\n",
    "    # Take the first 'num_files' files\n",
    "    selected_files = files[:num_files]\n",
    "\n",
    "    # Copy the selected files to the destination folder\n",
    "    for file in selected_files:\n",
    "        source_path = os.path.join(source_folder, file)\n",
    "        destination_path = os.path.join(destination_folder, file)\n",
    "        shutil.copyfile(source_path, destination_path)\n",
    "\n",
    "    print(f\"Mini dataset folder created with the first {num_files} files.\")\n",
    "\n",
    "create_mini_dataset(training_data_folder, mini_train_folder, 40)\n",
    "create_mini_dataset(label_data_folder, mini_label_folder, 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_train = mini_train_folder + \"/*.tif\"\n",
    "train_list = glob(pattern_train)\n",
    "\n",
    "pattern_label = mini_label_folder + \"/*.tif\"\n",
    "label_list = glob(pattern_label)\n",
    "\n",
    "# pattern_test = test_dir + \"/*.tif\"\n",
    "# test_list = glob(pattern_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = tiff.imread('/Users/carriexia/Desktop/spring_2023/computer_vision/kelp_competition/data/train/AA498489_satellite.tif')\n",
    "\n",
    "# # Get the shape of the image\n",
    "# shape = image.shape\n",
    "\n",
    "# print(\"Image shape:\", shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = tiff.imread('/Users/carriexia/Desktop/spring_2023/computer_vision/kelp_competition/data/label/AA498489_kelp.tif')\n",
    "\n",
    "# print(\"label image shape:\", image.shape)\n",
    "# image_array = np.array(image)\n",
    "\n",
    "# # Find the unique values in the image\n",
    "# unique_values = np.unique(image_array)\n",
    "# print(unique_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tensor_transform(list):\n",
    "#     for image in list:\n",
    "#         with tiff.tifffile(image) as temp:\n",
    "#             temp.asarray\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #  randomly print the map in training list\n",
    "# def show_image():\n",
    "#     n = np.random.randint(1,4509)\n",
    "#     with tiff.TiffFile(sorted(train_list)[n]) as train_temp:\n",
    "#         train = train_temp.asarray()\n",
    "#     with tiff.TiffFile(sorted(label_list)[n]) as label_temp:\n",
    "#         label = label_temp.asarray()\n",
    "\n",
    "#     n_channels = train.shape[2]\n",
    "\n",
    "#     plt.figure(figsize=(20, 10))  # Adjust the size as needed\n",
    "\n",
    "#     # Add the single image as the first subplot\n",
    "#     plt.subplot(2, 4, 1)  # Consider it's placed in a 2x4 grid\n",
    "#     plt.imshow(label)  # Assuming it's grayscale; adjust as needed\n",
    "#     plt.title('Kelp Image Label')\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     # Loop through each channel of the satellite image and add as subsequent subplots\n",
    "#     for i in range(n_channels):\n",
    "#         plt.subplot(2, 4, i + 2)  # Offset by 2 to account for the first kelp image\n",
    "#         plt.imshow(train[:, :, i])  # Display each channel in grayscale\n",
    "#         plt.title(f'Channel {i+1}')\n",
    "#         plt.axis('off')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "# show_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in training folder: 40\n",
      "Number of files in label folder: 40\n"
     ]
    }
   ],
   "source": [
    "def count_files_in_folder(folder):\n",
    "    # Get list of filenames in the folder\n",
    "    files = os.listdir(folder)\n",
    "    \n",
    "    # Count the number of files\n",
    "    num_files = len(files)\n",
    "    \n",
    "    return num_files\n",
    "\n",
    "# Example usage:\n",
    "num_files_in_folder1 = count_files_in_folder(mini_train_folder)\n",
    "print(f\"Number of files in training folder: {num_files_in_folder1}\")\n",
    "# Example usage:\n",
    "num_files_in_folder1 = count_files_in_folder(mini_label_folder)\n",
    "print(f\"Number of files in label folder: {num_files_in_folder1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All filenames in both folders have the same prefixes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_folders(folder1, folder2):\n",
    "    # Get list of filenames in each folder\n",
    "    files1 = sorted(os.listdir(folder1))\n",
    "    files2 = sorted(os.listdir(folder2))\n",
    "    \n",
    "    for file1, file2 in zip(files1, files2):\n",
    "        # Split filenames by underscore and compare the first part\n",
    "        name1 = file1.split('_')[0]\n",
    "        name2 = file2.split('_')[0]\n",
    "        \n",
    "        if name1 != name2:\n",
    "            print(f\"Files '{file1}' and '{file2}' have different prefixes.\")\n",
    "            return False\n",
    "    \n",
    "    print(\"All filenames in both folders have the same prefixes.\")\n",
    "    return True\n",
    "\n",
    "\n",
    "compare_folders(mini_train_folder, mini_label_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class auto_dataset():\n",
    "    def __init__(self, folder_train: Path, folder_target: Path, split_type=\"train\", val_size=0.2) -> None:\n",
    "        self.split_type = split_type\n",
    "        # Populate file paths\n",
    "        self.fpaths = glob(folder_train + \"/*\")\n",
    "        self.tpaths = glob(folder_target + \"/*\")\n",
    "    \n",
    "        # Calculate split index based on val_size\n",
    "        split_index = int(len(self.fpaths) * (1 - val_size))\n",
    "    \n",
    "        # Create indices for train and val sets\n",
    "        indices = list(range(len(self.fpaths)))\n",
    "        if split_type == \"train\":\n",
    "            self.train_indices = indices[:split_index]\n",
    "        elif split_type == \"val\":\n",
    "            self.val_indices = indices[split_index:]\n",
    "        elif split_type == \"all\":\n",
    "            self.train_indices = indices\n",
    "            self.val_indices = list(range(len(self.tpaths)))\n",
    "        \n",
    "        # Initialize MinMaxScaler\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        if self.split_type == \"train\":\n",
    "            return len(self.train_indices)\n",
    "        elif self.split_type == \"val\":\n",
    "            return len(self.val_indices)\n",
    "        elif self.split_type == \"all\":\n",
    "            return len(self.train_indices) + len(self.val_indices)\n",
    "    \n",
    "    def __getitem__(self, index) -> Tuple[torch.Tensor]:\n",
    "        with tiff.TiffFile(self.fpaths[index]) as train_temp:\n",
    "            train = train_temp.asarray()\n",
    "            # Normalize train data using MinMaxScaler\n",
    "            train = self.scaler.fit_transform(train.reshape(-1, 1)).reshape(train.shape)\n",
    "\n",
    "        with tiff.TiffFile(self.tpaths[index]) as label_temp:\n",
    "            label = label_temp.asarray()\n",
    "            # Normalize label data using MinMaxScaler\n",
    "            label = self.scaler.fit_transform(label.reshape(-1, 1)).reshape(label.shape)\n",
    "            \n",
    "        return torch.Tensor(train).permute(2, 0, 1).to(device=device), torch.Tensor(label).to(device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 1:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 2:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 3:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 4:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 5:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 6:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 7:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 8:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 9:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 10:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 11:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 12:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 13:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 14:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 15:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 16:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 17:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 18:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 19:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 20:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 21:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 22:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 23:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 24:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 25:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 26:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 27:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 28:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 29:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 30:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 31:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 32:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n"
     ]
    }
   ],
   "source": [
    "# Initialize train and validation datasets\n",
    "train_dataset = auto_dataset(mini_train_folder, mini_label_folder, split_type=\"train\", val_size=0.2)\n",
    "val_dataset = auto_dataset(mini_train_folder, mini_label_folder, split_type=\"val\", val_size=0.2)\n",
    "for i in range(len(train_dataset)):\n",
    "    train_data, label_data = train_dataset[i]\n",
    "    print(f\"Item {i+1}:\")\n",
    "    print(f\"Train data shape: {train_data.shape}\")\n",
    "    print(f\"Label data shape: {label_data.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 1:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 2:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 3:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 4:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 5:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 6:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 7:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n",
      "Item 8:\n",
      "Train data shape: torch.Size([7, 350, 350])\n",
      "Label data shape: torch.Size([350, 350])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(val_dataset)):\n",
    "    train_data, label_data = val_dataset[i]\n",
    "    print(f\"Item {i+1}:\")\n",
    "    print(f\"Train data shape: {train_data.shape}\")\n",
    "    print(f\"Label data shape: {label_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Length: 32\n",
      "Validation Dataset Length: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Dataset Length:\", len(train_dataset))\n",
    "print(\"Validation Dataset Length:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 8\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "            return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, features\n",
    "        ):\n",
    "            super(UNET, self).__init__()\n",
    "            self.ups = nn.ModuleList()\n",
    "            self.downs = nn.ModuleList()\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "            # Down part\n",
    "            for feature in features:\n",
    "                self.downs.append(DoubleConv(in_channels, feature))\n",
    "                in_channels = feature\n",
    "\n",
    "            # UP sampling part\n",
    "            for feature in reversed(features):\n",
    "                self.ups.append(\n",
    "                    nn.ConvTranspose2d(\n",
    "                        feature*2, feature, kernel_size=2, stride=2,\n",
    "                        )\n",
    "                )\n",
    "                self.ups.append(DoubleConv(feature*2, feature))\n",
    "            self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "            self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"Input size:\", x.size())\n",
    "        \n",
    "        skip_connections = []\n",
    "        for idx, down in enumerate(self.downs):\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "            print(f\"Down {idx + 1} output size:\", x.size())\n",
    "        \n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = TF.resize(x, skip_connection.shape[2:])\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "            print(f\"Up {idx // 2 + 1} output size:\", x.size())\n",
    "            \n",
    "        output = self.final_conv(x)\n",
    "        print(\"Final output size:\", output.size())\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the U-Net model with 7 input channels and 1 output channel\n",
    "in_channels = 7  # Number of input channels\n",
    "out_channels = 1  # Number of output channels\n",
    "features = [64, 128, 256, 512]\n",
    "model = UNET(in_channels, out_channels, features)\n",
    "# Specify data type (e.g., torch.float32)\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1cd141fc940>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: torch.Size([8, 7, 350, 350])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 240.00 MiB. GPU 0 has a total capacty of 8.00 GiB of which 0 bytes is free. Of the allocated memory 7.05 GiB is allocated by PyTorch, and 233.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Compute the loss\u001b[39;00m\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n",
      "File \u001b[1;32mc:\\Users\\guoyy\\miniconda3\\envs\\torchcv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\guoyy\\miniconda3\\envs\\torchcv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[62], line 31\u001b[0m, in \u001b[0;36mUNET.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     29\u001b[0m skip_connections \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, down \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdowns):\n\u001b[1;32m---> 31\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     skip_connections\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[0;32m     33\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x)\n",
      "File \u001b[1;32mc:\\Users\\guoyy\\miniconda3\\envs\\torchcv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\guoyy\\miniconda3\\envs\\torchcv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[61], line 13\u001b[0m, in \u001b[0;36mDoubleConv.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guoyy\\miniconda3\\envs\\torchcv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\guoyy\\miniconda3\\envs\\torchcv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\guoyy\\miniconda3\\envs\\torchcv\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\guoyy\\miniconda3\\envs\\torchcv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\guoyy\\miniconda3\\envs\\torchcv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\guoyy\\miniconda3\\envs\\torchcv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guoyy\\miniconda3\\envs\\torchcv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 240.00 MiB. GPU 0 has a total capacty of 8.00 GiB of which 0 bytes is free. Of the allocated memory 7.05 GiB is allocated by PyTorch, and 233.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for ix, data in enumerate(iter(train_loader)):\n",
    "        inputs, targets = data\n",
    "\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs).squeeze(1)\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
